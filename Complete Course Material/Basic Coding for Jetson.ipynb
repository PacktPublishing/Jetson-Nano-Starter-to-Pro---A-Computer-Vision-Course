{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision using OpenCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Read and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(image, caption = ' '):\n",
    "    plt.figure(figsize = (5, 10))\n",
    "    plt.title(caption) \n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "image = cv2.imread('lena.jpg') \n",
    "display(image, 'Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Conversion \n",
    "- BGR to RGB \n",
    "- BGR to GRAY \n",
    "- BGR to HSV \n",
    "- BGR to YCrCb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "YCrCb = cv2.cvtColor(image,cv2.COLOR_BGR2YCrCb) \n",
    "\n",
    "display(rgb, 'RGB Image')\n",
    "display(gray, 'Gray Image')\n",
    "display(hsv, 'HSV Image')\n",
    "display(YCrCb, 'YCrCB Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Filteration \n",
    "\n",
    "- Adding Noise\n",
    "- Image Smoothing \n",
    "- Median Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def Blur(image = None, k = 5, s = 1):\n",
    "    kernel = (5,5)\n",
    "    sigma = 2\n",
    "    blur = cv2.GaussianBlur(image,kernel,sigma)\n",
    "    return blur\n",
    "\n",
    "def add_noise(noisy_image = None):\n",
    "\n",
    "    row,col,_ = noisy_image.shape\n",
    "    number_of_pixels = random.randint(300, 1000)\n",
    "    for i in range(number_of_pixels):\n",
    "        y_coord=random.randint(0, row - 1)\n",
    "        x_coord=random.randint(0, col - 1)          \n",
    "        noisy_image[y_coord][x_coord][0] = 255\n",
    "        noisy_image[y_coord][x_coord][1] = 255\n",
    "        noisy_image[y_coord][x_coord][2] = 255\n",
    "\n",
    "    for i in range(number_of_pixels):\n",
    "        y_coord=random.randint(0, row - 1)\n",
    "        x_coord=random.randint(0, col - 1)\n",
    "        noisy_image[y_coord][x_coord][0] = 0\n",
    "        noisy_image[y_coord][x_coord][1] = 0\n",
    "        noisy_image[y_coord][x_coord][2] = 0\n",
    "        \n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    noisy_image = add_noise(rgb.copy())\n",
    "    image_blur = Blur(noisy_image.copy(), 5, 2) \n",
    "    median = cv2.medianBlur(noisy_image.copy(),5) \n",
    "    img = cv2.Laplacian(image.copy(),cv2.CV_8UC3)\n",
    "    \n",
    "\n",
    "    #Display all results\n",
    "    display(rgb, 'Original Image')\n",
    "    display(noisy_image, 'Noisy Image')\n",
    "    display(image_blur, 'Blurred Image')\n",
    "    display(median, 'Median of Image')\n",
    "    display(img, 'Laplacian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Transofrmation \n",
    "\n",
    "- Scaling \n",
    "- Translation\n",
    "- Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translation(image,x = 1,y = 1):\n",
    "    h,w,_ = image.shape\n",
    "    mat = np.float32([[1,0,x],[0,1,y]])\n",
    "    trans = cv2.warpAffine(image,mat,(h,w))\n",
    "    \n",
    "    return trans\n",
    "\n",
    "def Scaling(image,x = 1,y = 1):\n",
    "    h,w,_ = image.shape\n",
    "    mat = np.float32([[x,0,0],[0,y,0]])\n",
    "    scale = cv2.warpAffine(image,mat,(h,w))\n",
    "    \n",
    "    return scale \n",
    "\n",
    "def Rotation(image,theta = 0):\n",
    "    \n",
    "    h,w,_ = image.shape\n",
    "    center = (w/2, h/2)\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(center, angle = theta, scale=1)\n",
    "    rotated_image = cv2.warpAffine(image, rotate_matrix, (w, h))\n",
    "    \n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    img = rgb.copy()\n",
    "    scaling = Scaling(img,2)\n",
    "    \n",
    "    translation = Translation(img,100)\n",
    "    \n",
    "    rotation = Rotation(img,45)\n",
    "    \n",
    "    display(scaling, 'Scaled Image')\n",
    "    display(translation, 'Translated Image')\n",
    "    display(rotation, 'Rotated Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection \n",
    "\n",
    "- Laplacian \n",
    "- Sobel\n",
    "- Canny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_img = gray.copy()\n",
    "\n",
    "lap = cv2.Laplacian(orig_img,cv2.CV_8UC1)\n",
    "\n",
    "sobelx = cv2.Sobel(orig_img,cv2.CV_8UC1,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(orig_img,cv2.CV_8UC1,0,1,ksize=5)\n",
    "\n",
    "canny = cv2.Canny(orig_img,100,150)\n",
    "\n",
    "display(orig_img, 'Original Image')\n",
    "display(lap, 'Laplcian')\n",
    "display(sobelx, 'Sobel along X-axis')\n",
    "display(sobely, 'Sobel along Y-axis')\n",
    "display(canny, 'Canny Edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological Operations\n",
    "\n",
    "- Erosion \n",
    "- Dilation \n",
    "- Opening \n",
    "- Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "orig_img = canny.copy()\n",
    "erosion = cv2.erode(orig_img,kernel,iterations = 2)\n",
    "dilation = cv2.dilate(orig_img,kernel,iterations = 2)\n",
    "opening = cv2.morphologyEx(orig_img,cv2.MORPH_OPEN,kernel,iterations = 2)\n",
    "closing = cv2.morphologyEx(orig_img,cv2.MORPH_CLOSE,kernel,iterations = 2)\n",
    "\n",
    "display(orig_img, 'Original Image')\n",
    "display(erosion, 'Erosion')\n",
    "display(dilation, 'Dilation')\n",
    "display(opening, 'Opening')\n",
    "display(closing, 'Closing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Detection (Harris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_corners = rgb.copy()\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray_img = np.float32(gray_img)\n",
    "corners = cv2.cornerHarris(gray_img, blockSize=2, ksize=3, k=0.04)\n",
    "corners = cv2.dilate(corners, None)\n",
    "img_corners[corners > 0.01 * corners.max()] = [0, 255, 0]\n",
    "\n",
    "display(rgb, 'Original Image')\n",
    "display(img_corners, 'Corners Detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors \n",
    "Tensors are similar to NumPyâ€™s ndarrays, except that tensors can run on GPUs or other hardware accelerators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.tensor(10)\n",
    "b = torch.tensor(11)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a+b\n",
    "print(c)\n",
    "print(type(c))\n",
    "print(c.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    c = c.to('cuda')\n",
    "    \n",
    "c.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "np_array = np.array(data)\n",
    "tensor_array = torch.from_numpy(np_array)\n",
    "\n",
    "print(type(np_array))\n",
    "print(type(tensor_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random = torch.rand((3,3))\n",
    "ones = torch.ones((3,3))\n",
    "zeros = torch.zeros((3,3))\n",
    "\n",
    "print(f\"Random Tensor: \\n {random} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros}\")\n",
    "\n",
    "print(f\"Shape: {random.shape}\")\n",
    "print(f\"Datatype: {random.dtype}\")\n",
    "print(f\"Stored on Device: {random.device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = rand_tensor\n",
    "y1 = tensor\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "multiply = torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "add = tensor.sum()\n",
    "add = add.item()\n",
    "\n",
    "print(multiply)\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Random Images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
